{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing ConvNet on dummy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "# import needed stuff\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "# verify tensorflow installation\n",
    "print(\"TensorFlow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image files\n",
    "DATADIR = \"C:/Users/gabriel.l.santiago/Documents/PetImages\"\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "MODEL_NAME = \"Cats-vs-dogs-128x2-3conv-Dense0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images\n",
    "IMG_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "# create training set\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) # path to pics\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "create_training_data()\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# randomize training data\n",
    "random.shuffle(training_data)\n",
    "\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])\n",
    "\n",
    "# prepare data for modeling\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "X = X/255.0\n",
    "\n",
    "# number of features\n",
    "layer_size = 128\n",
    "\n",
    "# setup model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(layer_size, (3,3), input_shape = X.shape[1:])) # conv layer\n",
    "model.add(Activation(\"relu\")) # activation\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # pooling layer\n",
    "\n",
    "model.add(Conv2D(layer_size, (3,3))) # another conv layer\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(layer_size, (3,3))) # another conv layer\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten()) # flatten layers from 1D -> 2D\n",
    "\n",
    "# dense layer\n",
    "# model.add(Dense(layer_size))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tensorboard as keras callback\n",
    "NAME = MODEL_NAME, \"-{}\".format(int(time.time()))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/20\n",
      "17462/17462 [==============================] - 101s 6ms/sample - loss: 0.6480 - accuracy: 0.6167 - val_loss: 0.5827 - val_accuracy: 0.7098\n",
      "Epoch 2/20\n",
      "17462/17462 [==============================] - 574s 33ms/sample - loss: 0.5458 - accuracy: 0.7244 - val_loss: 0.5006 - val_accuracy: 0.7568\n",
      "Epoch 3/20\n",
      "17462/17462 [==============================] - 96s 6ms/sample - loss: 0.4791 - accuracy: 0.7692 - val_loss: 0.4629 - val_accuracy: 0.7855\n",
      "Epoch 4/20\n",
      "17462/17462 [==============================] - 98s 6ms/sample - loss: 0.4356 - accuracy: 0.7940 - val_loss: 0.4705 - val_accuracy: 0.7850\n",
      "Epoch 5/20\n",
      "17462/17462 [==============================] - 102s 6ms/sample - loss: 0.3926 - accuracy: 0.8237 - val_loss: 0.4350 - val_accuracy: 0.8029\n",
      "Epoch 6/20\n",
      "17462/17462 [==============================] - 100s 6ms/sample - loss: 0.3497 - accuracy: 0.8435 - val_loss: 0.4199 - val_accuracy: 0.8092\n",
      "Epoch 7/20\n",
      "17462/17462 [==============================] - 98s 6ms/sample - loss: 0.3146 - accuracy: 0.8640 - val_loss: 0.4082 - val_accuracy: 0.8260\n",
      "Epoch 8/20\n",
      "17462/17462 [==============================] - 96s 5ms/sample - loss: 0.2809 - accuracy: 0.8793 - val_loss: 0.4667 - val_accuracy: 0.8071\n",
      "Epoch 9/20\n",
      "17462/17462 [==============================] - 97s 6ms/sample - loss: 0.2401 - accuracy: 0.9001 - val_loss: 0.4322 - val_accuracy: 0.8210\n",
      "Epoch 10/20\n",
      "17462/17462 [==============================] - 101s 6ms/sample - loss: 0.2111 - accuracy: 0.9136 - val_loss: 0.4494 - val_accuracy: 0.8203\n",
      "Epoch 11/20\n",
      "17462/17462 [==============================] - 98s 6ms/sample - loss: 0.1731 - accuracy: 0.9325 - val_loss: 0.4844 - val_accuracy: 0.8137\n",
      "Epoch 12/20\n",
      "17462/17462 [==============================] - 107s 6ms/sample - loss: 0.1451 - accuracy: 0.9436 - val_loss: 0.4971 - val_accuracy: 0.8239\n",
      "Epoch 13/20\n",
      "17462/17462 [==============================] - 102s 6ms/sample - loss: 0.1230 - accuracy: 0.9520 - val_loss: 0.5549 - val_accuracy: 0.8184\n",
      "Epoch 14/20\n",
      "17462/17462 [==============================] - 99s 6ms/sample - loss: 0.0957 - accuracy: 0.9661 - val_loss: 0.6369 - val_accuracy: 0.8145\n",
      "Epoch 15/20\n",
      "17462/17462 [==============================] - 99s 6ms/sample - loss: 0.0775 - accuracy: 0.9730 - val_loss: 0.6394 - val_accuracy: 0.8211\n",
      "Epoch 16/20\n",
      "17462/17462 [==============================] - 100s 6ms/sample - loss: 0.0655 - accuracy: 0.9771 - val_loss: 0.6974 - val_accuracy: 0.8192\n",
      "Epoch 17/20\n",
      "17462/17462 [==============================] - 97s 6ms/sample - loss: 0.0521 - accuracy: 0.9825 - val_loss: 0.7705 - val_accuracy: 0.8014\n",
      "Epoch 18/20\n",
      "17462/17462 [==============================] - 102s 6ms/sample - loss: 0.0395 - accuracy: 0.9885 - val_loss: 0.9552 - val_accuracy: 0.7954\n",
      "Epoch 19/20\n",
      "17462/17462 [==============================] - 107s 6ms/sample - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.8484 - val_accuracy: 0.8071\n",
      "Epoch 20/20\n",
      "17462/17462 [==============================] - 101s 6ms/sample - loss: 0.0417 - accuracy: 0.9852 - val_loss: 0.9126 - val_accuracy: 0.8089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa1bcbcef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "# launch tensorboard: tensorboard --logdir logs\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=20, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gabriel.l.santiago\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: Cats-vs-dogs-128x2-3conv-Dense0\\assets\n"
     ]
    }
   ],
   "source": [
    "# save model \n",
    "model.save(MODEL_NAME, \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model on images\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    new_array = np.array(new_array).astype(np.float32)\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# model = tf.keras.models.load_model(\"Cats-vs-dogs-64x2-3conv-Dense1.model\")\n",
    "model = tf.keras.models.load_model(\"Cats-vs-dogs-64x2-3conv-Dense0\")\n",
    "# model = tf.keras.models.load_model(\"Cats-vs-dogs-128x2-3conv-Dense0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "# ALWAYS pass a list even if one prediction only\n",
    "prediction = model.predict([prepare('cat1.jpg')])\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
